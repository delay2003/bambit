{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0120bambit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J4IqZ31mzrW",
        "colab_type": "code",
        "outputId": "f00957af-2538-47ec-93a9-48c2b16e7502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCVDKf-SpLB0",
        "colab_type": "code",
        "outputId": "69a30d66-cfcb-4641-e0c3-faad6bb087ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/gdrive/My Drive/bambit/UrbanSound8K'\n",
        "!cp -rf '/gdrive/My Drive/bambit/UrbanSound8K' /contents"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "audio  FREESOUNDCREDITS.txt  metadata  UrbanSound8K_README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwZbUsoNh_1I",
        "colab_type": "code",
        "outputId": "8c1f65fd-2b52-472a-8359-e7e8643b2aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "!ls /contents/audio"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold1  fold10  fold2  fold3  fold4  fold5  fold6  fold7  fold8\tfold9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ2dkylNs7z_",
        "colab_type": "code",
        "outputId": "356466cd-b77f-4b23-e56c-2fdc01a27371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import librosa \n",
        "from scipy.io import wavfile as wav\n",
        "import numpy as np\n",
        "\n",
        "filename = '/contents/audio/fold5/100852-0-0-0.wav' \n",
        "\n",
        "librosa_audio, librosa_sample_rate = librosa.load(filename) \n",
        "scipy_sample_rate, scipy_audio = wav.read(filename) \n",
        "\n",
        "print('Original sample rate:', scipy_sample_rate) \n",
        "print('Librosa sample rate:', librosa_sample_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sample rate: 44100\n",
            "Librosa sample rate: 22050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4EJFarsqhoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(file_name):\n",
        "   \n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file_name)\n",
        "        return None \n",
        "     \n",
        "    return mfccsscaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj9V6Cadqmzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load various imports \n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "# Set the path to the full UrbanSound dataset \n",
        "fulldatasetpath = '/contents/audio/'\n",
        "\n",
        "metadata = pd.read_csv('/contents/metadata/UrbanSound8K.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc1G1Jwig_lj",
        "colab_type": "code",
        "outputId": "ee5fcde8-f979-4d0e-e1cb-b506d5cfd780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "features = []\n",
        "\n",
        "# Iterate through each sound file and extract the features \n",
        "for index, row in metadata.iterrows():\n",
        "    \n",
        "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "    \n",
        "    class_label = row[\"class\"]\n",
        "    data = extract_features(file_name)\n",
        "    \n",
        "    features.append([data, class_label])\n",
        "\n",
        "# Convert into a Panda dataframe \n",
        "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
        "\n",
        "print('Finished feature extraction from ', len(featuresdf), ' files')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished feature extraction from  8732  files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVOZH1Nyripy",
        "colab_type": "code",
        "outputId": "f2d5f2fc-a422-49e0-f896-3795a34281f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(featuresdf.feature.tolist())\n",
        "y = np.array(featuresdf.class_label.tolist())\n",
        "\n",
        "# Encode the classification labels\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZf096FWtqsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset \n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ArbXrH92lD",
        "colab_type": "code",
        "outputId": "d9e167b8-fd7d-418f-86a0-56cd3f126ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "%store x_train \n",
        "%store x_test \n",
        "%store y_train \n",
        "%store y_test \n",
        "%store yy \n",
        "%store le"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stored 'x_train' (ndarray)\n",
            "Stored 'x_test' (ndarray)\n",
            "Stored 'y_train' (ndarray)\n",
            "Stored 'y_test' (ndarray)\n",
            "Stored 'yy' (ndarray)\n",
            "Stored 'le' (LabelEncoder)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc0krY6Z96HF",
        "colab_type": "code",
        "outputId": "08754ac3-8846-4bbb-c1be-b77cd0ef4a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics \n",
        "\n",
        "num_labels = yy.shape[1]\n",
        "filter_size = 2\n",
        "\n",
        "# Construct model \n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(256, input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o66aqxbp-U7r",
        "colab_type": "code",
        "outputId": "65b48ee2-dfac-4f9b-c44c-ab80f479e272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqwQMwGCFisH",
        "colab_type": "code",
        "outputId": "67d89bd6-4ef5-457e-a04b-385e001258df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        }
      },
      "source": [
        "# Display model architecture summary \n",
        "model.summary()\n",
        "\n",
        "# Calculate pre-training accuracy \n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               10496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 78,858\n",
            "Trainable params: 78,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Pre-training accuracy: 12.1923%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBD5TwDq2A-6",
        "colab_type": "code",
        "outputId": "0f0c7bbf-c19c-47ea-aa5b-fed1931aee3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  saved_models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6HfQaQrFo5E",
        "colab_type": "code",
        "outputId": "58317785-95c8-43e2-d176-667598ec6825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint \n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 100\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6985 samples, validate on 1747 samples\n",
            "Epoch 1/100\n",
            "6985/6985 [==============================] - 1s 140us/step - loss: 1.4424 - acc: 0.5081 - val_loss: 1.2357 - val_acc: 0.6073\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23570, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 2/100\n",
            "6985/6985 [==============================] - 1s 138us/step - loss: 1.3735 - acc: 0.5304 - val_loss: 1.1725 - val_acc: 0.6491\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23570 to 1.17248, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 3/100\n",
            "6985/6985 [==============================] - 1s 142us/step - loss: 1.3056 - acc: 0.5573 - val_loss: 1.1094 - val_acc: 0.6623\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.17248 to 1.10942, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 4/100\n",
            "6985/6985 [==============================] - 1s 163us/step - loss: 1.2534 - acc: 0.5694 - val_loss: 1.0494 - val_acc: 0.6760\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.10942 to 1.04936, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 5/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 1.1933 - acc: 0.6014 - val_loss: 0.9858 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.04936 to 0.98582, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 6/100\n",
            "6985/6985 [==============================] - 1s 142us/step - loss: 1.1571 - acc: 0.6100 - val_loss: 0.9457 - val_acc: 0.7104\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.98582 to 0.94570, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 7/100\n",
            "6985/6985 [==============================] - 1s 138us/step - loss: 1.1281 - acc: 0.6143 - val_loss: 0.9239 - val_acc: 0.7023\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.94570 to 0.92390, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 8/100\n",
            "6985/6985 [==============================] - 1s 133us/step - loss: 1.0935 - acc: 0.6252 - val_loss: 0.8527 - val_acc: 0.7172\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.92390 to 0.85267, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 9/100\n",
            "6985/6985 [==============================] - 1s 151us/step - loss: 1.0685 - acc: 0.6369 - val_loss: 0.8746 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.85267\n",
            "Epoch 10/100\n",
            "6985/6985 [==============================] - 1s 137us/step - loss: 1.0311 - acc: 0.6464 - val_loss: 0.8217 - val_acc: 0.7464\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.85267 to 0.82168, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 11/100\n",
            "6985/6985 [==============================] - 1s 128us/step - loss: 0.9706 - acc: 0.6679 - val_loss: 0.7867 - val_acc: 0.7447\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.82168 to 0.78672, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 12/100\n",
            "6985/6985 [==============================] - 1s 143us/step - loss: 0.9609 - acc: 0.6681 - val_loss: 0.7896 - val_acc: 0.7516\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.78672\n",
            "Epoch 13/100\n",
            "6985/6985 [==============================] - 1s 140us/step - loss: 0.9468 - acc: 0.6789 - val_loss: 0.7499 - val_acc: 0.7699\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.78672 to 0.74987, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 14/100\n",
            "6985/6985 [==============================] - 1s 128us/step - loss: 0.9125 - acc: 0.6911 - val_loss: 0.7128 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.74987 to 0.71276, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 15/100\n",
            "6985/6985 [==============================] - 1s 146us/step - loss: 0.9030 - acc: 0.6889 - val_loss: 0.7146 - val_acc: 0.7699\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.71276\n",
            "Epoch 16/100\n",
            "6985/6985 [==============================] - 1s 142us/step - loss: 0.8942 - acc: 0.7026 - val_loss: 0.6812 - val_acc: 0.7951\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.71276 to 0.68118, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 17/100\n",
            "6985/6985 [==============================] - 1s 128us/step - loss: 0.8519 - acc: 0.7125 - val_loss: 0.6378 - val_acc: 0.8048\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.68118 to 0.63780, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 18/100\n",
            "6985/6985 [==============================] - 1s 134us/step - loss: 0.8511 - acc: 0.7084 - val_loss: 0.6495 - val_acc: 0.7922\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.63780\n",
            "Epoch 19/100\n",
            "6985/6985 [==============================] - 1s 143us/step - loss: 0.8262 - acc: 0.7223 - val_loss: 0.6479 - val_acc: 0.8031\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.63780\n",
            "Epoch 20/100\n",
            "6985/6985 [==============================] - 1s 129us/step - loss: 0.8254 - acc: 0.7158 - val_loss: 0.6173 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.63780 to 0.61731, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 21/100\n",
            "6985/6985 [==============================] - 1s 152us/step - loss: 0.7875 - acc: 0.7287 - val_loss: 0.6331 - val_acc: 0.8037\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.61731\n",
            "Epoch 22/100\n",
            "6985/6985 [==============================] - 1s 139us/step - loss: 0.7985 - acc: 0.7323 - val_loss: 0.6107 - val_acc: 0.8054\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.61731 to 0.61070, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 23/100\n",
            "6985/6985 [==============================] - 1s 164us/step - loss: 0.7815 - acc: 0.7389 - val_loss: 0.5968 - val_acc: 0.8174\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.61070 to 0.59680, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 24/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 0.7622 - acc: 0.7400 - val_loss: 0.5703 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.59680 to 0.57032, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 25/100\n",
            "6985/6985 [==============================] - 1s 146us/step - loss: 0.7598 - acc: 0.7422 - val_loss: 0.5706 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.57032\n",
            "Epoch 26/100\n",
            "6985/6985 [==============================] - 1s 137us/step - loss: 0.7535 - acc: 0.7416 - val_loss: 0.5848 - val_acc: 0.8226\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.57032\n",
            "Epoch 27/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 0.7441 - acc: 0.7439 - val_loss: 0.5592 - val_acc: 0.8191\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.57032 to 0.55917, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 28/100\n",
            "6985/6985 [==============================] - 1s 134us/step - loss: 0.7304 - acc: 0.7472 - val_loss: 0.5508 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.55917 to 0.55084, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 29/100\n",
            "6985/6985 [==============================] - 1s 148us/step - loss: 0.7223 - acc: 0.7543 - val_loss: 0.5398 - val_acc: 0.8329\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.55084 to 0.53980, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 30/100\n",
            "6985/6985 [==============================] - 1s 134us/step - loss: 0.7255 - acc: 0.7479 - val_loss: 0.5565 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.53980\n",
            "Epoch 31/100\n",
            "6985/6985 [==============================] - 1s 140us/step - loss: 0.7138 - acc: 0.7591 - val_loss: 0.5412 - val_acc: 0.8346\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.53980\n",
            "Epoch 32/100\n",
            "6985/6985 [==============================] - 1s 130us/step - loss: 0.7070 - acc: 0.7599 - val_loss: 0.5151 - val_acc: 0.8357\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.53980 to 0.51507, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 33/100\n",
            "6985/6985 [==============================] - 1s 151us/step - loss: 0.6890 - acc: 0.7669 - val_loss: 0.5332 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.51507\n",
            "Epoch 34/100\n",
            "6985/6985 [==============================] - 1s 142us/step - loss: 0.6862 - acc: 0.7682 - val_loss: 0.4957 - val_acc: 0.8454\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.51507 to 0.49573, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 35/100\n",
            "6985/6985 [==============================] - 1s 140us/step - loss: 0.6894 - acc: 0.7682 - val_loss: 0.5130 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.49573\n",
            "Epoch 36/100\n",
            "6985/6985 [==============================] - 1s 131us/step - loss: 0.6738 - acc: 0.7745 - val_loss: 0.5012 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.49573\n",
            "Epoch 37/100\n",
            "6985/6985 [==============================] - 1s 127us/step - loss: 0.6799 - acc: 0.7692 - val_loss: 0.5116 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.49573\n",
            "Epoch 38/100\n",
            "6985/6985 [==============================] - 1s 126us/step - loss: 0.6667 - acc: 0.7712 - val_loss: 0.5031 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.49573\n",
            "Epoch 39/100\n",
            "6985/6985 [==============================] - 1s 124us/step - loss: 0.6780 - acc: 0.7702 - val_loss: 0.5050 - val_acc: 0.8374\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.49573\n",
            "Epoch 40/100\n",
            "6985/6985 [==============================] - 1s 124us/step - loss: 0.6426 - acc: 0.7759 - val_loss: 0.4842 - val_acc: 0.8409\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.49573 to 0.48421, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 41/100\n",
            "6985/6985 [==============================] - 1s 123us/step - loss: 0.6674 - acc: 0.7744 - val_loss: 0.4797 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.48421 to 0.47965, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 42/100\n",
            "6985/6985 [==============================] - 1s 132us/step - loss: 0.6658 - acc: 0.7711 - val_loss: 0.4900 - val_acc: 0.8454\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.47965\n",
            "Epoch 43/100\n",
            "6985/6985 [==============================] - 1s 145us/step - loss: 0.6404 - acc: 0.7830 - val_loss: 0.4892 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.47965\n",
            "Epoch 44/100\n",
            "6985/6985 [==============================] - 1s 135us/step - loss: 0.6492 - acc: 0.7802 - val_loss: 0.4886 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.47965\n",
            "Epoch 45/100\n",
            "6985/6985 [==============================] - 1s 151us/step - loss: 0.6231 - acc: 0.7934 - val_loss: 0.4653 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.47965 to 0.46527, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 46/100\n",
            "6985/6985 [==============================] - 1s 138us/step - loss: 0.6206 - acc: 0.7897 - val_loss: 0.4576 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.46527 to 0.45760, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 47/100\n",
            "6985/6985 [==============================] - 1s 144us/step - loss: 0.6103 - acc: 0.7924 - val_loss: 0.4795 - val_acc: 0.8552\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.45760\n",
            "Epoch 48/100\n",
            "6985/6985 [==============================] - 1s 148us/step - loss: 0.6207 - acc: 0.7870 - val_loss: 0.4726 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.45760\n",
            "Epoch 49/100\n",
            "6985/6985 [==============================] - 1s 164us/step - loss: 0.6174 - acc: 0.7960 - val_loss: 0.4711 - val_acc: 0.8506\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.45760\n",
            "Epoch 50/100\n",
            "6985/6985 [==============================] - 1s 150us/step - loss: 0.6126 - acc: 0.7964 - val_loss: 0.4676 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.45760\n",
            "Epoch 51/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 0.6076 - acc: 0.7936 - val_loss: 0.4772 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.45760\n",
            "Epoch 52/100\n",
            "6985/6985 [==============================] - 1s 132us/step - loss: 0.5961 - acc: 0.7960 - val_loss: 0.4902 - val_acc: 0.8558\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.45760\n",
            "Epoch 53/100\n",
            "6985/6985 [==============================] - 1s 145us/step - loss: 0.6255 - acc: 0.7904 - val_loss: 0.4448 - val_acc: 0.8695\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.45760 to 0.44481, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 54/100\n",
            "6985/6985 [==============================] - 1s 133us/step - loss: 0.6183 - acc: 0.7921 - val_loss: 0.4780 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.44481\n",
            "Epoch 55/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 0.5957 - acc: 0.7964 - val_loss: 0.4384 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.44481 to 0.43839, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 56/100\n",
            "6985/6985 [==============================] - 1s 130us/step - loss: 0.5863 - acc: 0.8011 - val_loss: 0.4742 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.43839\n",
            "Epoch 57/100\n",
            "6985/6985 [==============================] - 1s 128us/step - loss: 0.5937 - acc: 0.8016 - val_loss: 0.4426 - val_acc: 0.8683\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.43839\n",
            "Epoch 58/100\n",
            "6985/6985 [==============================] - 1s 123us/step - loss: 0.5863 - acc: 0.8019 - val_loss: 0.4538 - val_acc: 0.8655\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.43839\n",
            "Epoch 59/100\n",
            "6985/6985 [==============================] - 1s 135us/step - loss: 0.6245 - acc: 0.7903 - val_loss: 0.4705 - val_acc: 0.8615\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.43839\n",
            "Epoch 60/100\n",
            "6985/6985 [==============================] - 1s 131us/step - loss: 0.6019 - acc: 0.7999 - val_loss: 0.4638 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.43839\n",
            "Epoch 61/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 0.5646 - acc: 0.8064 - val_loss: 0.4423 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.43839\n",
            "Epoch 62/100\n",
            "6985/6985 [==============================] - 1s 150us/step - loss: 0.6145 - acc: 0.7980 - val_loss: 0.4584 - val_acc: 0.8672\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.43839\n",
            "Epoch 63/100\n",
            "6985/6985 [==============================] - 1s 139us/step - loss: 0.5905 - acc: 0.7981 - val_loss: 0.4460 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.43839\n",
            "Epoch 64/100\n",
            "6985/6985 [==============================] - 1s 141us/step - loss: 0.5760 - acc: 0.8083 - val_loss: 0.4277 - val_acc: 0.8741\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.43839 to 0.42768, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 65/100\n",
            "6985/6985 [==============================] - 1s 165us/step - loss: 0.5853 - acc: 0.8011 - val_loss: 0.4335 - val_acc: 0.8741\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.42768\n",
            "Epoch 66/100\n",
            "6985/6985 [==============================] - 1s 132us/step - loss: 0.5470 - acc: 0.8152 - val_loss: 0.4376 - val_acc: 0.8764\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.42768\n",
            "Epoch 67/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 0.5841 - acc: 0.8047 - val_loss: 0.4440 - val_acc: 0.8689\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.42768\n",
            "Epoch 68/100\n",
            "6985/6985 [==============================] - 1s 149us/step - loss: 0.5771 - acc: 0.7991 - val_loss: 0.4371 - val_acc: 0.8701\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.42768\n",
            "Epoch 69/100\n",
            "6985/6985 [==============================] - 1s 138us/step - loss: 0.5806 - acc: 0.8027 - val_loss: 0.4384 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.42768\n",
            "Epoch 70/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 0.5814 - acc: 0.8000 - val_loss: 0.4439 - val_acc: 0.8666\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.42768\n",
            "Epoch 71/100\n",
            "6985/6985 [==============================] - 1s 134us/step - loss: 0.5637 - acc: 0.8110 - val_loss: 0.4125 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.42768 to 0.41255, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 72/100\n",
            "6985/6985 [==============================] - 1s 133us/step - loss: 0.5644 - acc: 0.8106 - val_loss: 0.4273 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.41255\n",
            "Epoch 73/100\n",
            "6985/6985 [==============================] - 1s 137us/step - loss: 0.5610 - acc: 0.8105 - val_loss: 0.4280 - val_acc: 0.8752\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.41255\n",
            "Epoch 74/100\n",
            "6985/6985 [==============================] - 1s 152us/step - loss: 0.5581 - acc: 0.8146 - val_loss: 0.4359 - val_acc: 0.8672\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.41255\n",
            "Epoch 75/100\n",
            "6985/6985 [==============================] - 1s 126us/step - loss: 0.5813 - acc: 0.8080 - val_loss: 0.4425 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.41255\n",
            "Epoch 76/100\n",
            "6985/6985 [==============================] - 1s 123us/step - loss: 0.5699 - acc: 0.8092 - val_loss: 0.4241 - val_acc: 0.8729\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.41255\n",
            "Epoch 77/100\n",
            "6985/6985 [==============================] - 1s 138us/step - loss: 0.5599 - acc: 0.8125 - val_loss: 0.4147 - val_acc: 0.8764\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.41255\n",
            "Epoch 78/100\n",
            "6985/6985 [==============================] - 1s 122us/step - loss: 0.5458 - acc: 0.8178 - val_loss: 0.4343 - val_acc: 0.8729\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.41255\n",
            "Epoch 79/100\n",
            "6985/6985 [==============================] - 1s 134us/step - loss: 0.5447 - acc: 0.8186 - val_loss: 0.4208 - val_acc: 0.8729\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.41255\n",
            "Epoch 80/100\n",
            "6985/6985 [==============================] - 1s 141us/step - loss: 0.5565 - acc: 0.8166 - val_loss: 0.4102 - val_acc: 0.8815\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.41255 to 0.41020, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 81/100\n",
            "6985/6985 [==============================] - 1s 144us/step - loss: 0.5440 - acc: 0.8126 - val_loss: 0.4214 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.41020\n",
            "Epoch 82/100\n",
            "6985/6985 [==============================] - 1s 147us/step - loss: 0.5340 - acc: 0.8190 - val_loss: 0.4272 - val_acc: 0.8769\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.41020\n",
            "Epoch 83/100\n",
            "6985/6985 [==============================] - 1s 137us/step - loss: 0.5501 - acc: 0.8129 - val_loss: 0.4185 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.41020\n",
            "Epoch 84/100\n",
            "6985/6985 [==============================] - 1s 137us/step - loss: 0.5670 - acc: 0.8157 - val_loss: 0.4197 - val_acc: 0.8752\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.41020\n",
            "Epoch 85/100\n",
            "6985/6985 [==============================] - 1s 131us/step - loss: 0.5597 - acc: 0.8162 - val_loss: 0.4146 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.41020\n",
            "Epoch 86/100\n",
            "6985/6985 [==============================] - 1s 136us/step - loss: 0.5409 - acc: 0.8218 - val_loss: 0.4150 - val_acc: 0.8775\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.41020\n",
            "Epoch 87/100\n",
            "6985/6985 [==============================] - 1s 133us/step - loss: 0.5634 - acc: 0.8145 - val_loss: 0.4273 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.41020\n",
            "Epoch 88/100\n",
            "6985/6985 [==============================] - 1s 123us/step - loss: 0.5492 - acc: 0.8178 - val_loss: 0.4378 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.41020\n",
            "Epoch 89/100\n",
            "6985/6985 [==============================] - 1s 143us/step - loss: 0.5449 - acc: 0.8175 - val_loss: 0.4176 - val_acc: 0.8752\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.41020\n",
            "Epoch 90/100\n",
            "6985/6985 [==============================] - 1s 142us/step - loss: 0.5394 - acc: 0.8208 - val_loss: 0.4520 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.41020\n",
            "Epoch 91/100\n",
            "6985/6985 [==============================] - 1s 140us/step - loss: 0.5519 - acc: 0.8192 - val_loss: 0.4394 - val_acc: 0.8769\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.41020\n",
            "Epoch 92/100\n",
            "6985/6985 [==============================] - 1s 131us/step - loss: 0.5291 - acc: 0.8304 - val_loss: 0.4208 - val_acc: 0.8769\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.41020\n",
            "Epoch 93/100\n",
            "6985/6985 [==============================] - 1s 132us/step - loss: 0.5312 - acc: 0.8218 - val_loss: 0.4122 - val_acc: 0.8661\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.41020\n",
            "Epoch 94/100\n",
            "6985/6985 [==============================] - 1s 144us/step - loss: 0.5398 - acc: 0.8218 - val_loss: 0.4365 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.41020\n",
            "Epoch 95/100\n",
            "6985/6985 [==============================] - 1s 149us/step - loss: 0.5341 - acc: 0.8186 - val_loss: 0.4021 - val_acc: 0.8821\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.41020 to 0.40210, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 96/100\n",
            "6985/6985 [==============================] - 1s 135us/step - loss: 0.5327 - acc: 0.8245 - val_loss: 0.4097 - val_acc: 0.8775\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.40210\n",
            "Epoch 97/100\n",
            "6985/6985 [==============================] - 1s 149us/step - loss: 0.5215 - acc: 0.8285 - val_loss: 0.3941 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.40210 to 0.39412, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 98/100\n",
            "6985/6985 [==============================] - 1s 149us/step - loss: 0.5337 - acc: 0.8196 - val_loss: 0.4033 - val_acc: 0.8821\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.39412\n",
            "Epoch 99/100\n",
            "6985/6985 [==============================] - 1s 154us/step - loss: 0.5124 - acc: 0.8269 - val_loss: 0.4189 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.39412\n",
            "Epoch 100/100\n",
            "6985/6985 [==============================] - 1s 137us/step - loss: 0.5323 - acc: 0.8203 - val_loss: 0.4114 - val_acc: 0.8775\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.39412\n",
            "Training completed in time:  0:01:37.904190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RErR0g_BFDOG",
        "colab_type": "code",
        "outputId": "7a017bb7-6f70-4a58-ed71-82f78d925baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy:  0.9294201861130995\n",
            "Testing Accuracy:  0.8775042929032495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uZgeZsU38G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa \n",
        "import numpy as np \n",
        "\n",
        "def extract_feature(file_name):\n",
        "   \n",
        "    try:\n",
        "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
        "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file)\n",
        "        return None, None\n",
        "\n",
        "    return np.array([mfccsscaled])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hDtklbG3f8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_prediction(file_name):\n",
        "    prediction_feature = extract_feature(file_name) \n",
        "\n",
        "    predicted_vector = model.predict_classes(prediction_feature)\n",
        "    predicted_class = le.inverse_transform(predicted_vector) \n",
        "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
        "\n",
        "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
        "    predicted_proba = predicted_proba_vector[0]\n",
        "    for i in range(len(predicted_proba)): \n",
        "        category = le.inverse_transform(np.array([i]))\n",
        "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqzVSYkOOa_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_noise_result(file_name):\n",
        "    prediction_feature = extract_feature(file_name) \n",
        "\n",
        "    predicted_vector = model.predict_classes(prediction_feature)\n",
        "    predicted_class = le.inverse_transform(predicted_vector) \n",
        "    if predicted_class[0] == 'children_playing':\n",
        "      noise_result = 2\n",
        "    elif predicted_class[0] == 'siren':\n",
        "      noise_result = 1\n",
        "    else:\n",
        "      noise_result = 0\n",
        "    \n",
        "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
        "    print(\"The noise result is:\", noise_result, '\\n') \n",
        "\n",
        "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
        "    predicted_proba = predicted_proba_vector[0]\n",
        "    for i in range(len(predicted_proba)): \n",
        "        category = le.inverse_transform(np.array([i]))\n",
        "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuJmeoRyPL8R",
        "colab_type": "code",
        "outputId": "cc926898-a191-4aec-9946-1557130726c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Class: Air Conditioner\n",
        "\n",
        "filename = '/contents/audio/fold5/100852-0-0-0.wav' \n",
        "print_noise_result(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is: air_conditioner \n",
            "\n",
            "The noise result is: 0 \n",
            "\n",
            "air_conditioner \t\t :  0.99878376722335815429687500000000\n",
            "car_horn \t\t :  0.00004398046439746394753456115723\n",
            "children_playing \t\t :  0.00014643651957157999277114868164\n",
            "dog_bark \t\t :  0.00001793673800420947372913360596\n",
            "drilling \t\t :  0.00008701449405634775757789611816\n",
            "engine_idling \t\t :  0.00012476820847950875759124755859\n",
            "gun_shot \t\t :  0.00000043521950487956928554922342\n",
            "jackhammer \t\t :  0.00000362312516699603293091058731\n",
            "siren \t\t :  0.00000142965348004508996382355690\n",
            "street_music \t\t :  0.00079056678805500268936157226562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao3zheJZ3pmu",
        "colab_type": "code",
        "outputId": "3bf87357-c4bc-47a8-f45d-7e6488c72486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Class: Air Conditioner\n",
        "\n",
        "filename = '/contents/audio/fold5/100852-0-0-0.wav' \n",
        "print_prediction(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is: air_conditioner \n",
            "\n",
            "air_conditioner \t\t :  0.99878376722335815429687500000000\n",
            "car_horn \t\t :  0.00004398046439746394753456115723\n",
            "children_playing \t\t :  0.00014643651957157999277114868164\n",
            "dog_bark \t\t :  0.00001793673800420947372913360596\n",
            "drilling \t\t :  0.00008701449405634775757789611816\n",
            "engine_idling \t\t :  0.00012476820847950875759124755859\n",
            "gun_shot \t\t :  0.00000043521950487956928554922342\n",
            "jackhammer \t\t :  0.00000362312516699603293091058731\n",
            "siren \t\t :  0.00000142965348004508996382355690\n",
            "street_music \t\t :  0.00079056678805500268936157226562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WrAm08j31iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -rf '/gdrive/My Drive/bambit/test' /contents/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rRKawjv5-Ah",
        "colab_type": "code",
        "outputId": "20d2e18e-73c2-44f9-ecae-5ad4f9de02ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls /contents/test/test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bambit_car.wav\tbambit_noise2.wav  bambit_none.wav\n",
            "bambit_dog.wav\tbambit_noise.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O9bpQ3m51YK",
        "colab_type": "code",
        "outputId": "742be8fc-267a-450b-99d1-36d415d092ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Class: test dog\n",
        "\n",
        "filename = '/contents/test/test/bambit_dog.wav' \n",
        "print_prediction(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is: dog_bark \n",
            "\n",
            "air_conditioner \t\t :  0.00000000000000494976747035438119\n",
            "car_horn \t\t :  0.00000000000075801642523617984715\n",
            "children_playing \t\t :  0.00560012506321072578430175781250\n",
            "dog_bark \t\t :  0.85162252187728881835937500000000\n",
            "drilling \t\t :  0.00000027476880859467200934886932\n",
            "engine_idling \t\t :  0.00000196007749764248728752136230\n",
            "gun_shot \t\t :  0.07898790389299392700195312500000\n",
            "jackhammer \t\t :  0.00000000000000000007343951170081\n",
            "siren \t\t :  0.06378713995218276977539062500000\n",
            "street_music \t\t :  0.00000000429464241946675429062452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKgDU1hx6e_V",
        "colab_type": "code",
        "outputId": "7f233459-a544-412c-cbe3-e224011d328a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Class: test dog\n",
        "\n",
        "filename = '/contents/test/test/bambit_car.wav' \n",
        "print_prediction(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is: car_horn \n",
            "\n",
            "air_conditioner \t\t :  0.00000000167660274552616783694248\n",
            "car_horn \t\t :  0.92860049009323120117187500000000\n",
            "children_playing \t\t :  0.04645843431353569030761718750000\n",
            "dog_bark \t\t :  0.00088880391558632254600524902344\n",
            "drilling \t\t :  0.00000050550767127788276411592960\n",
            "engine_idling \t\t :  0.00007015214214334264397621154785\n",
            "gun_shot \t\t :  0.00000448200853497837670147418976\n",
            "jackhammer \t\t :  0.00000000003082153282596422627648\n",
            "siren \t\t :  0.00002990590292029082775115966797\n",
            "street_music \t\t :  0.02394720539450645446777343750000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VdsDkoH-5Xq",
        "colab_type": "code",
        "outputId": "b1d99e6a-8a59-4fff-81da-4cd3677a87d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Class: test dog\n",
        "\n",
        "filename = '/contents/test/test/bambit_noise.wav' \n",
        "print_prediction(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is: dog_bark \n",
            "\n",
            "air_conditioner \t\t :  0.00000000012908010771361944080127\n",
            "car_horn \t\t :  0.00000218026070797350257635116577\n",
            "children_playing \t\t :  0.47461932897567749023437500000000\n",
            "dog_bark \t\t :  0.48877233266830444335937500000000\n",
            "drilling \t\t :  0.00031312881037592887878417968750\n",
            "engine_idling \t\t :  0.00010077881597680971026420593262\n",
            "gun_shot \t\t :  0.02418982423841953277587890625000\n",
            "jackhammer \t\t :  0.00000000000032440039153189270671\n",
            "siren \t\t :  0.01194657012820243835449218750000\n",
            "street_music \t\t :  0.00005585378676187247037887573242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ej5LwD_W9T",
        "colab_type": "code",
        "outputId": "9d5c5122-51e1-40fb-edba-2ae651b2d682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Class: test dog\n",
        "\n",
        "filename = '/contents/test/test/bambit_noise2.wav' \n",
        "print_prediction(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is: dog_bark \n",
            "\n",
            "air_conditioner \t\t :  0.00000375115473616460803896188736\n",
            "car_horn \t\t :  0.00027904461603611707687377929688\n",
            "children_playing \t\t :  0.32156893610954284667968750000000\n",
            "dog_bark \t\t :  0.41897258162498474121093750000000\n",
            "drilling \t\t :  0.02036360651254653930664062500000\n",
            "engine_idling \t\t :  0.00202078768052160739898681640625\n",
            "gun_shot \t\t :  0.21995028853416442871093750000000\n",
            "jackhammer \t\t :  0.00000005274942793676018482074142\n",
            "siren \t\t :  0.01236956007778644561767578125000\n",
            "street_music \t\t :  0.00447144499048590660095214843750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRz9HAi2BVK_",
        "colab_type": "code",
        "outputId": "36735727-03bb-47aa-ed9a-114905640036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Class: test dog\n",
        "\n",
        "filename = '/contents/test/test/bambit_none.wav' \n",
        "print_prediction(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is: gun_shot \n",
            "\n",
            "air_conditioner \t\t :  0.00000002533727894160620053298771\n",
            "car_horn \t\t :  0.00001981199602596461772918701172\n",
            "children_playing \t\t :  0.01890042237937450408935546875000\n",
            "dog_bark \t\t :  0.34305316209793090820312500000000\n",
            "drilling \t\t :  0.00221340986900031566619873046875\n",
            "engine_idling \t\t :  0.00000658176850265590474009513855\n",
            "gun_shot \t\t :  0.63526213169097900390625000000000\n",
            "jackhammer \t\t :  0.00000000002097384245447475592528\n",
            "siren \t\t :  0.00054224615450948476791381835938\n",
            "street_music \t\t :  0.00000213638213608646765351295471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7qz_CMC_epk",
        "colab_type": "code",
        "outputId": "ea70d00b-2c06-4f61-ff5b-82fcae21965a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Example of a confusion matrix in Python\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "expected = [1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
        "predicted = [1, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
        "results = confusion_matrix(expected, predicted)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 2]\n",
            " [1 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Hp6U4iCLoB",
        "colab_type": "code",
        "outputId": "4a573448-8df4-4702-ea8f-d6e286cddf51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "\n",
        "# fail나면 root계정에서  \"pip install seaborn\" 명령 실행할 것. \n",
        "\n",
        "import seaborn as sn\n",
        "\n",
        "df_cm = pd.DataFrame(results, range(2),\n",
        "                  range(2))\n",
        "plt.figure(figsize = (10,7))\n",
        "\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcee1315dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGfCAYAAACNytIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYgQA6EoxAgB0pRgBALpSjAAAXf1foYL5BIH0JEQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjk1B9sxCOxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}